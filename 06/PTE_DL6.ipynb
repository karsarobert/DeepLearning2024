{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSRvpAW2xiz162O3qsNkIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karsarobert/DeepLearning2024/blob/main/06/PTE_DL6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1e098a6CJVa"
      },
      "outputs": [],
      "source": [
        "# Adatok beolvasása CSV fájlból Pandas DataFrame-be\n",
        "import pandas as pd\n",
        "dataframe = pd.read_csv('file.csv')\n",
        "\n",
        "# Adatok beolvasása URL-ről Pandas DataFrame-be\n",
        "import pandas as pd\n",
        "dataframe = pd.read_csv('http://url/file.csv')\n",
        "\n",
        "# Adatok NumPy tömbbé alakítása\n",
        "import pandas as pd\n",
        "data = dataframe.values\n",
        "\n",
        "# Címkék kinyerése az utolsó oszlopból\n",
        "labels = data[:, -1]\n",
        "\n",
        "# Adatok kinyerése az összes oszlopból, kivéve az utolsót\n",
        "data = data[:, 0:-1]\n",
        "\n",
        "# Adatok felosztása tréning és teszt halmazokra\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=21)\n",
        "\n",
        "# Adatok normalizálása [0, 1] intervallumra TensorFlow-val\n",
        "import tensorflow as tf\n",
        "min_val = tf.reduce_min(X_train)\n",
        "max_val = tf.reduce_max(X_train)\n",
        "X_train = (X_train - min_val) / (max_val - min_val)\n",
        "X_test = (X_test - min_val) / (max_val - min_val)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Adattípus konvertálása float32-re TensorFlow-val\n",
        "import tensorflow as tf\n",
        "X_train = tf.cast(X_train, tf.float32)\n",
        "X_test = tf.cast(X_test, tf.float32)\n",
        "\n",
        "# Logikai tömbbé alakítás\n",
        "train_labels = train_labels.astype(bool)\n",
        "test_labels = test_labels.astype(bool)\n",
        "\n",
        "# Normál adatok szűrése logikai indexeléssel\n",
        "normal_train_data = train_data[train_labels]\n",
        "normal_test_data = test_data[test_labels]\n",
        "\n",
        "# Anomáliás adatok szűrése negált logikai indexeléssel\n",
        "anomalous_train_data = train_data[~train_labels]\n",
        "anomalous_test_data = test_data[~test_labels]\n",
        "\n",
        "# Egyedi értékek megszámlálása egy NumPy tömbben\n",
        "import numpy as np\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "# One-hot kódolás Keras-szal\n",
        "import tensorflow as tf\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Szekvenciális modell létrehozása Keras-szal\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Sűrű réteg hozzáadása a modellhez\n",
        "model.add(layers.Dense(units=64, activation='relu', input_shape=[input_dim]))\n",
        "\n",
        "# Dropout réteg hozzáadása\n",
        "model.add(layers.Dropout(rate=0.3))\n",
        "\n",
        "# Batch normalizáció hozzáadása\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Kimeneti réteg hozzáadása regresszióhoz\n",
        "model.add(layers.Dense(units=1))\n",
        "\n",
        "# Kimeneti réteg hozzáadása bináris osztályozáshoz\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Kimeneti réteg hozzáadása többosztályos osztályozáshoz\n",
        "model.add(layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Modell fordítása regresszióhoz\n",
        "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "\n",
        "# Modell fordítása bináris osztályozáshoz\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Modell fordítása többosztályos osztályozáshoz\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Korai leállítás visszahívás definiálása\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(min_delta=0.001, patience=20, restore_best_weights=True)\n",
        "\n",
        "# Modell illesztése tréning adatokra, validációval és korai leállítással\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=256, epochs=500, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "# Tanulási görbék ábrázolása\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
        "\n",
        "# Modell kiértékelése teszt adatokon\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Előrejelzés készítése új adatokon\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Modell mentése\n",
        "model.save(\"my_model.h5\")\n",
        "\n",
        "# Modell betöltése\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model(\"my_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "\n",
        "# Adatok betöltése és előkészítése\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "y = raw_df.values[1::2, 2]"
      ],
      "metadata": {
        "id": "pANVSfWtCsEk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}